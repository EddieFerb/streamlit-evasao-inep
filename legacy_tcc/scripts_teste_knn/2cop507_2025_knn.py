# -*- coding: utf-8 -*-
"""2COP507-2025-kNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16dRCp7ppSX0t5FevRccJ1nNSeoiiljmg

# Reconhecimento de Padrões - k Nearest Neighbors
Bruno Bogaz Zarpelão <br>
brunozarpelao@uel.br

# Reconhecimento de Padrões
<hr><h3>Lazy learners</h3>
<ul>
    <li>o kNN (k-nearest-neighbor) é um exemplo de lazy learner.</li>
    <li>Ao contrário dos eager learners, os lazy learners, quando recebem uma amostra de treinamento, apenas guardam ela.</li>
    <li>Quando os lazy learners recebem um amostra de teste, eles realizam a generalização. Geralmente, classificam a amostra de teste de acordo com a classe da(s) amostra(s) de treino mais similar(es) a ela.</li>
    <li>São conhecidos também como instance-based learners.</li>
    <li>Normalmente, demandam bastante capacidade computacional, em termos de processamento e armazenamento. Não produzem um modelo compacto.</li>
    <li>Oferecem suporte a aprendizado incremental, ou seja, a base de treinamento pode ser atualizada conforme aparecem novas amostras rotuladas, sem a necessidade de se executar novamente um algoritmo de treinamento. </li>
</ul>

# Reconhecimento de Padrões
<hr><h3>kNN</h3>
<ul>
    <li>Descrito pela primeira vez nos anos 50.</li>
    <li>Aprendizado por analogia.</li>
    <li> Uma vez que recebe uma amostra de teste, o algoritmo faz uma busca no espaço do problema pelos k vizinhos mais próximos. Estes vizinhos devem estar rotulados, pois constituem a base de treinamento. O rótulo destes vizinhos é usado para determinar o rótulo da amostra de teste.</li>
    <li> A distância entre a amostra de teste e os vizinhos é calculada por meio da distância Euclidiana. </li>

</ul>

# Reconhecimento de Padrões

## Distância Euclidiana

*   A distância Euclidiana entre dois vetores de features é calculada da seguinte forma: $\sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$.
*   O uso da distância Euclidiana implica na necessidade de normalizar as features envolvidas.
* A distância Euclidiana é adequada para valores numéricos. Valores categóricos, por exemplo, devem ser pré-processados.
* A escolha da distância pode ser crítica para o desempenho do modelo. Outras distâncias, como a distância de Mahalanobis, podem ser escolhidas.

# Reconhecimento de Padrões
## Escolha do valor de k
* O valor de k pode ser determinado de maneira experimental.
* Pode iniciar-se com k=1 e ir aumentando esse valor, enquanto mede-se o desempenho do classificador para cada caso.
* Seleciona-se o k que produziu os melhores resultados de capacidade preditiva (menor erro).
* Em geral, quanto maior o tamanho da base de treinamento, maior o valor de k.

# Classificação com KNN

Neste experimento, vamos utilizar o algoritmo **K-Nearest Neighbors (KNN)** para classificar a sobrevivência no Titanic com base em características dos passageiros. Vamos abordar a importância da normalização das variáveis numéricas, o pré-processamento de variáveis categóricas, e estratégias de validação como hold-out e cross-validation.

Além disso, aprenderemos a selecionar o valor de **K** mais adequado para o nosso classificador, e exploraremos a **matriz de confusão** e outras métricas de desempenho.

## Carregamento e Visualização dos Dados

Vamos utilizar o conhecido **dataset do Titanic**. As features incluem variáveis numéricas, como a idade e a tarifa paga, e variáveis categóricas, como o sexo e a classe da passagem.
"""

import pandas as pd

# Carregar o dataset Titanic
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)

# Visualizar os primeiros dados
df.head()

"""## Pré-processamento: Lidando com Valores Faltantes

O dataset Titanic contém alguns valores ausentes, que precisam ser tratados antes de aplicar o KNN.

"""

# Verificar valores faltantes
print ("valores faltantes: ")
print(df.isnull().sum())

# Preencher valores ausentes
#como 'Age' é um valor contínuo, preenchemos os faltantes com a mediana da coluna
df['Age'] = df['Age'].fillna(df['Age'].median())
#como 'Embarked' é um valor discreto, preenchemos os faltantes com a moda da coluna
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
df.drop(columns=['Cabin'], inplace=True)  # Remover a coluna 'Cabin' pela alta quantidade de valores faltantes

# Confirmar que não há mais valores ausentes
print ("valores faltantes após pré-processamento: ")
print(df.isnull().sum())

"""## Normalização das Variáveis Numéricas

Como o KNN é sensível à escala, vamos normalizar as variáveis numéricas como 'Age' e 'Fare'.

"""

from sklearn.preprocessing import StandardScaler

# Selecionar variáveis numéricas
numerical_features = ['Age', 'Fare']

# Aplicar normalização
scaler = StandardScaler()
df[numerical_features] = scaler.fit_transform(df[numerical_features])

# Exibir os dados normalizados
df.head()

"""## Tratamento de Features Categóricas

As variáveis categóricas precisam ser convertidas para numéricas. Vamos usar **One-Hot Encoding** para as colunas 'Sex' e 'Embarked'.

"""

from sklearn.preprocessing import OneHotEncoder

# Aplicar one-hot encoding nas colunas 'Sex' e 'Embarked'
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Excluir colunas desnecessárias
df.drop(columns=['PassengerId', 'Name', 'Ticket'], inplace=True)

# Visualizar o dataset processado
df.head()

"""## Hold-Out e Seleção do Melhor K

Agora, vamos dividir o dataset em treino e teste, e testar diferentes valores de K para escolher o mais adequado.

"""

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Definir variáveis de entrada (X) e alvo (y)
X = df.drop(columns=['Survived'])
y = df['Survived']

# Dividir o dataset
# Execute múltiplas vezes alterando o random_state e perceba como o melhor k pode variar
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)

# Testar diferentes valores de K
best_k = 1
best_accuracy = 0

for k in range(1, 21):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"K = {k}, Acurácia: {accuracy:.2f}")

    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_k = k

print(f"Melhor valor de K: {best_k} com acurácia de {best_accuracy:.2f}")

"""## Cross-Validation

Agora, vamos validar o modelo com **5-fold cross-validation** para verificar sua performance em diferentes subconjuntos do dataset.

"""

from sklearn.model_selection import cross_val_score

# Cross-validation com o melhor K
knn = KNeighborsClassifier(n_neighbors=best_k)
scores = cross_val_score(knn, X, y, cv=5)

print(f"Acurácias no cross-validation: {scores}")
print(f"Média da acurácia: {scores.mean():.2f}")

"""## Avaliação do Desempenho

A **matriz de confusão** é fundamental para entender a performance do modelo. Vamos também calcular a precisão, recall e F1-score.

"""

from sklearn.metrics import confusion_matrix, classification_report, f1_score


#Para que esse código funcione, deve-se executar antes o código mais acima com o método hold-out, não com o cross-validation
# Previsões no conjunto de teste
y_pred = knn.predict(X_test)

# Matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred)
print(f"Matriz de Confusão:\n{conf_matrix}")

#f1-score
print(f"f1-score:{f1_score(y_test, y_pred)}")

# Relatório de classificação
print(classification_report(y_test, y_pred))

"""# Conclusão

Neste experimento, utilizamos o KNN para classificar a sobrevivência no Titanic, com foco em normalização de variáveis numéricas, pré-processamento de variáveis categóricas, e seleção de hiperparâmetros. Avaliamos o modelo com hold-out, cross-validation e usamos a matriz de confusão e outras métricas de desempenho para entender seus resultados.

# Exercício 1
Faça o mesmo exercício, mas **não** normalize o valor das features. Há uma diferença de desempenho preditivo?

# Exercício 2: Predição de Doença Cardíaca com KNN

## Objetivo:
Neste exercício, você aplicará o algoritmo KNN para prever a presença de doença cardíaca em pacientes. Você deve focar no pré-processamento dos dados, escolha de K, e validação do modelo. Calcule a capacidade preditiva do modelo utilizando a estratégia cross-validation e a estratégia hold-out.

## Instruções:

### 1. Carregamento do Dataset:
O dataset Heart Disease pode ser carregado a partir de um repositório público, como o do UCI Machine Learning. Utilize o seguinte link para carregar os dados: https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data. Mais informações sobre o dataset podem ser encontradas em: https://archive.ics.uci.edu/dataset/45/heart+disease.

# Exercício 3: Classificação de Espécies de Íris com KNN

## Objetivo
Neste exercício, você aplicará o algoritmo KNN para classificar diferentes espécies de flores íris com base em medidas de suas características. Você deve trabalhar com o pré-processamento dos dados, escolha do valor de K, e validação do modelo usando hold-out e cross-validation. Além disso, você irá avaliar o desempenho do modelo utilizando a matriz de confusão e outras métricas.

## Dataset
Você usará o famoso dataset "Iris" que está disponível no [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/iris). Este dataset contém medidas de 150 flores íris de três espécies diferentes.

### 1. Carregamento do Dataset
Carregue o dataset Iris a partir do repositório UCI e faça a leitura em um DataFrame do pandas.

```python
import pandas as pd

# URL para o dataset Iris no UCI Machine Learning Repository
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"

# Definir os nomes das colunas
column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']

# Carregar o dataset
df = pd.read_csv(url, names=column_names, delimiter=',')

# Visualizar as primeiras linhas do dataset
df.head()

#Exercício 4: kNN para problemas de regressão

## Fundamentação
Você sabia que é possível utilizar o kNN parra problemas de regressão? Neste caso, ao invés de definir uma classe a partir dos k vizinhos mais próximos, ele calcula o valor da predição como a média dos valores determinados pelos k vizinhos mais próximos.

## Objetivo
Criar e avaliar um modelo de regressão baseado em kNN para o conjunto de dados California Housing. Ao final, comparar as métricas obtidas com o kNN com aquelas obtidas na aula anterior com regressão linear.

## Etapas

1. Carregar e preparar o conjunto de dados.
2. Criar diferentes modelos baseados em kNN de forma a testar diferentes valores para k. Usar a estratégia hold-out.  
3. Plotar gráficos que mostrem os valores de MAE, MSE, MAPE e r2 obtidos para os diferentes k.
4. Escolher os melhores resultados e compará-los com os obtidos com a regressão linear.
"""