# # app_evasao.py
# # Dashboard interativo com an√°lise de evas√£o usando Streamlit

# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# import os

# BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# csv_path = os.path.join(BASE_DIR, '..', '..', 'dados', 'processado', 'dados_ingresso_evasao_conclusao.csv')
# df = pd.read_csv(csv_path, sep=';')

# st.set_page_config(page_title="Dashboard Evas√£o IES", layout="wide")

# # T√≠tulo
# st.title("üìä Dashboard - Taxas de Ingresso, Conclus√£o e Evas√£o")

# # Filtro por curso
# cursos = df['nome_curso'].unique()
# curso_selecionado = st.selectbox("Selecione um curso:", sorted(cursos))

# # Filtrar
# df_filtrado = df[df['nome_curso'] == curso_selecionado]

# # M√©tricas r√°pidas
# col1, col2, col3 = st.columns(3)
# col1.metric("Taxa de Ingresso (m√©dia)", f"{df_filtrado['taxa_ingresso'].mean():.2f}")
# col2.metric("Taxa de Conclus√£o (m√©dia)", f"{df_filtrado['taxa_conclusao'].mean():.2f}")
# col3.metric("Taxa de Evas√£o (m√©dia)", f"{df_filtrado['taxa_evasao'].mean():.2f}")

# # Gr√°fico de linha
# st.subheader("üìà Evolu√ß√£o das Taxas")
# fig, ax = plt.subplots(figsize=(10, 5))
# sns.lineplot(data=df_filtrado[['taxa_ingresso', 'taxa_conclusao', 'taxa_evasao']])
# st.pyplot(fig)

# # Salvar gr√°fico como imagem PNG
# output_dir = os.path.join(BASE_DIR, '..', '..', 'acessibilidade_web', 'graficos')
# os.makedirs(output_dir, exist_ok=True)
# fig.savefig(os.path.join(output_dir, 'grafico_taxas.png'))


import os
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix,
    f1_score,
    mean_absolute_error,
    mean_squared_error,
    precision_score,
    r2_score,
    recall_score,
)

# ===============================
#  LOCALIZA√á√ÉO DOS ARQUIVOS
# ===============================
BASE_DIR = Path(__file__).resolve().parents[2]
CAMINHO_DADOS = BASE_DIR / "dados" / "processado" / "dados_ingresso_evasao_conclusao.csv"
CAMINHO_MODELO_BASE = BASE_DIR / "modelos" / "modelos_salvos" / "modelo_melhor_evasao.pkl"


# ===============================
#  CONFIGURA√á√ÉO DO LAYOUT STREAMLIT
# ===============================
st.set_page_config(
    page_title="Predi√ß√£o de Evas√£o ‚Äî Ensino Superior",
    page_icon="üìâ",
    layout="wide",
)

st.sidebar.title("üìä Predi√ß√£o de Evas√£o")
st.sidebar.markdown("Aplica√ß√£o pr√°tica ‚Äî **2COP507 (Reconhecimento de Padr√µes)**")


# ===============================
#  CARREGAR BASE TRATADA
# ===============================
@st.cache_data(show_spinner=False)
def load_reference_data() -> pd.DataFrame:
    df = pd.read_csv(CAMINHO_DADOS, sep=";", encoding="utf-8", low_memory=False)
    return df


df_ref = load_reference_data()


# ===============================
#  CARREGAR MODELO BASE (TREINADO NO PIPELINE)
# ===============================
@st.cache_resource(show_spinner=False)
def load_base_model():
    modelo = joblib.load(CAMINHO_MODELO_BASE)
    return modelo


modelo_base = load_base_model()

# Colunas de entrada usadas no modelo (garante compatibilidade com o pickle)
if hasattr(modelo_base, "feature_names_in_"):
    FEATURE_COLS = list(modelo_base.feature_names_in_)
else:
    # fallback: usa o mesmo conjunto principal do pipeline
    FEATURE_COLS = [
        "numero_cursos",
        "vagas_totais",
        "inscritos_totais",
        "ingressantes",
        "matriculados",
        "concluintes",
    ]


# ===============================
#  FUN√á√ÉO PARA TREINO CUSTOMIZADO
# ===============================
@st.cache_resource(show_spinner=False)
def treinar_modelo_customizado(
    n_estimators: int,
    max_depth: int | None,
    min_samples_split: int,
):
    """Treina um RandomForestRegressor com hiperpar√¢metros escolhidos no sidebar."""

    df = df_ref.copy()

    X = df[FEATURE_COLS]
    y = df["taxa_evasao"]

    modelo = RandomForestRegressor(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        random_state=42,
        n_jobs=-1,
    )

    modelo.fit(X, y)
    return modelo


# ===============================
#  SIDEBAR ‚Äî SELE√á√ÉO DE HIPERPAR√ÇMETROS
# ===============================
st.sidebar.header("Ajuste de Hiperpar√¢metros")

algoritmo = st.sidebar.selectbox(
    "Algoritmo",
    ["RandomForest ‚Äî modelo do pipeline", "RandomForest ‚Äî customizado"],
)

n_estimators = st.sidebar.slider("N√∫mero de √Årvores (n_estimators)", 50, 500, 200, step=10)
max_depth = st.sidebar.slider("Profundidade M√°xima (max_depth)", 2, 30, 15)
min_samples_split = st.sidebar.slider("M√≠nimo de amostras para dividir o n√≥ (min_samples_split)", 2, 20, 4)

usar_custom = algoritmo == "RandomForest ‚Äî customizado"

if usar_custom:
    modelo_ativo = treinar_modelo_customizado(
        n_estimators=n_estimators,
        max_depth=max_depth,
        min_samples_split=min_samples_split,
    )
    st.sidebar.success("Usando modelo RandomForest **customizado** treinado em tempo real.")
else:
    modelo_ativo = modelo_base
    st.sidebar.info("Usando modelo RandomForest do **pipeline original** (pickle).")


# ===============================
#  FUN√á√ÉO AUXILIAR DE PR√â-PROCESSAMENTO
# ===============================
def preprocess_row(row: pd.Series) -> np.ndarray:
    """Recebe uma linha com FEATURES e devolve o array na ordem esperada pelo modelo."""

    row = row.copy()
    row = row[FEATURE_COLS]
    return row.values.reshape(1, -1)


# Estat√≠sticas para sugerir valores padr√£o na interface
stats = df_ref[FEATURE_COLS].describe()


# ===============================
#  TABS DA INTERFACE
# ===============================

tab1, tab2, tab3, tab4 = st.tabs(
    [
        "üìò Sobre a Aplica√ß√£o",
        "üìà Predi√ß√£o Individual",
        "üìä Avalia√ß√£o do Modelo",
        "üìÅ Enviar Arquivo",
    ]
)


# ===============================
#  TAB 1 ‚Äî SOBRE
# ===============================
with tab1:
    st.header("Sobre a Aplica√ß√£o")
    st.markdown(
        """
Esta aplica√ß√£o faz parte da disciplina **2COP507 ‚Äì Reconhecimento de Padr√µes** e utiliza
um modelo de **Random Forest** para estimar a **taxa de evas√£o** em cursos da educa√ß√£o superior.

### ‚úîÔ∏è O que voc√™ encontrar√° aqui
- Interface amig√°vel para experimentos com o modelo
- Ajuste interativo de hiperpar√¢metros do Random Forest
- M√©tricas de avalia√ß√£o (MAE, RMSE, R¬≤, acur√°cia bin√°ria, F1 etc.)
- Gr√°ficos: dispers√£o, distribui√ß√£o e matriz de confus√£o
- Upload de arquivo CSV para predi√ß√µes em lote

### üéØ Tecnologias utilizadas
- **Streamlit** ‚Äî interface web interativa
- **Scikit-Learn** ‚Äî RandomForestRegressor
- **Pandas / NumPy** ‚Äî manipula√ß√£o dos dados
- **Matplotlib / Seaborn** ‚Äî visualiza√ß√£o
"""
    )


# ===============================
#  TAB 2 ‚Äî PREDI√á√ÉO INDIVIDUAL
# ===============================
with tab2:
    st.header("üìà Predi√ß√£o Individual de Taxa de Evas√£o")
    st.markdown("Ajuste os valores das vari√°veis e clique em **Calcular**.")

    # Cria inputs num√©ricos com base nas FEATURES usadas no modelo
    cols = st.columns(3)
    valores_usuario = {}

    for idx, col_name in enumerate(FEATURE_COLS):
        col_streamlit = cols[idx % 3]
        desc = stats[col_name]
        default_val = float(desc["50%"])
        min_val = float(max(0, desc["min"]))
        max_val = float(desc["max"])

        with col_streamlit:
            valores_usuario[col_name] = st.number_input(
                f"{col_name}",
                min_value=min_val,
                max_value=max_val,
                value=default_val,
                step=max(1.0, (max_val - min_val) / 100),
            )

    if st.button("üîÆ Calcular probabilidade de evas√£o", key="btn_pred_individual"):
        df_user = pd.DataFrame([valores_usuario])
        x = preprocess_row(df_user.iloc[0])

        # RandomForestRegressor retorna valor cont√≠nuo de taxa de evas√£o
        taxa_predita = float(modelo_ativo.predict(x)[0])
        taxa_predita_clipped = float(np.clip(taxa_predita, 0.0, 1.0))

        # Interpreta√ß√£o bin√°ria simples (threshold 0.5)
        evasao_flag = int(taxa_predita_clipped >= 0.5)

        if evasao_flag == 1:
            st.error(f"üö® Probabilidade alta de evas√£o ‚Äî **{taxa_predita_clipped:.2%}**")
        else:
            st.success(f"‚úÖ Probabilidade maior de perman√™ncia ‚Äî evas√£o estimada em **{taxa_predita_clipped:.2%}**")

        st.metric("Taxa de evas√£o predita", f"{taxa_predita_clipped:.2%}")


# ===============================
#  TAB 3 ‚Äî AVALIA√á√ÉO DO MODELO
# ===============================
with tab3:
    st.header("üìä Avalia√ß√£o do Modelo")
    st.markdown("Avalia√ß√£o usando todo o conjunto consolidado `dados_ingresso_evasao_conclusao.csv`.")

    X = df_ref[FEATURE_COLS]
    y_continuo = df_ref["taxa_evasao"]

    # Predi√ß√£o cont√≠nua
    y_pred_cont = modelo_ativo.predict(X)

    # M√©tricas de regress√£o
    mae = mean_absolute_error(y_continuo, y_pred_cont)
    rmse = np.sqrt(mean_squared_error(y_continuo, y_pred_cont))
    r2 = r2_score(y_continuo, y_pred_cont)

    col1, col2, col3 = st.columns(3)
    col1.metric("MAE", f"{mae:.4f}")
    col2.metric("RMSE", f"{rmse:.4f}")
    col3.metric("R¬≤", f"{r2:.4f}")

    st.markdown("---")

    # Convers√£o para classifica√ß√£o bin√°ria (threshold 0.5)
    y_true_bin = (y_continuo >= 0.5).astype(int)
    y_pred_bin = (np.clip(y_pred_cont, 0.0, 1.0) >= 0.5).astype(int)

    acc = accuracy_score(y_true_bin, y_pred_bin)
    f1 = f1_score(y_true_bin, y_pred_bin)
    rec = recall_score(y_true_bin, y_pred_bin)
    prec = precision_score(y_true_bin, y_pred_bin)

    col4, col5, col6, col7 = st.columns(4)
    col4.metric("Acur√°cia (bin√°ria)", f"{acc:.4f}")
    col5.metric("F1-score", f"{f1:.4f}")
    col6.metric("Recall", f"{rec:.4f}")
    col7.metric("Precis√£o", f"{prec:.4f}")

    st.markdown("---")

    # Matriz de confus√£o
    cm = confusion_matrix(y_true_bin, y_pred_bin)
    fig_cm, ax_cm = plt.subplots(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, ax=ax_cm)
    ax_cm.set_xlabel("Predito")
    ax_cm.set_ylabel("Verdadeiro")
    ax_cm.set_title("Matriz de Confus√£o ‚Äî classifica√ß√£o bin√°ria da evas√£o")
    st.pyplot(fig_cm)

    st.markdown("---")

    # Dispers√£o real vs predito (regress√£o)
    fig_scatter, ax_scatter = plt.subplots(figsize=(6, 4))
    ax_scatter.scatter(y_continuo, y_pred_cont, alpha=0.3)
    ax_scatter.plot([0, 1], [0, 1], "r--", label="Linha ideal")
    ax_scatter.set_xlabel("Taxa de evas√£o real")
    ax_scatter.set_ylabel("Taxa de evas√£o predita")
    ax_scatter.set_title("Dispers√£o ‚Äî real vs predito")
    ax_scatter.legend()
    st.pyplot(fig_scatter)

    st.markdown("---")

    # Import√¢ncia das features
    if hasattr(modelo_ativo, "feature_importances_"):
        importancias = modelo_ativo.feature_importances_
        df_imp = pd.DataFrame({
            "feature": FEATURE_COLS,
            "importance": importancias,
        }).sort_values("importance", ascending=False)

        st.subheader("Import√¢ncia das vari√°veis (Random Forest)")
        fig_imp, ax_imp = plt.subplots(figsize=(6, 4))
        sns.barplot(data=df_imp, x="importance", y="feature", ax=ax_imp)
        ax_imp.set_xlabel("Import√¢ncia relativa")
        ax_imp.set_ylabel("Vari√°vel")
        st.pyplot(fig_imp)

        st.dataframe(df_imp.reset_index(drop=True))


# ===============================
#  TAB 4 ‚Äî UPLOAD DE CSV
# ===============================
with tab4:
    st.header("üìÅ Enviar Arquivo CSV para Previs√£o em Lote")
    st.markdown(
        "O arquivo deve conter **pelo menos** as colunas usadas pelo modelo:\n"
        f"`{', '.join(FEATURE_COLS)}`."
    )

    file = st.file_uploader("Envie um arquivo CSV", type=["csv"])

    if file is not None:
        df_upload = pd.read_csv(file)

        st.subheader("Pr√©-visualiza√ß√£o do arquivo enviado")
        st.dataframe(df_upload.head())

        # Verifica se todas as colunas necess√°rias existem
        missing = [c for c in FEATURE_COLS if c not in df_upload.columns]
        if missing:
            st.error(
                "As seguintes colunas obrigat√≥rias n√£o foram encontradas no CSV enviado: "
                + ", ".join(missing)
            )
        else:
            X_up = df_upload[FEATURE_COLS]
            y_pred_up = modelo_ativo.predict(X_up)
            y_pred_up_clipped = np.clip(y_pred_up, 0.0, 1.0)
            evasao_flag = (y_pred_up_clipped >= 0.5).astype(int)

            df_result = df_upload.copy()
            df_result["taxa_evasao_predita"] = y_pred_up_clipped
            df_result["evasao_alta"] = evasao_flag

            st.success("Predi√ß√µes geradas com sucesso!")
            st.dataframe(df_result.head())

            csv_bytes = df_result.to_csv(index=False).encode("utf-8")
            st.download_button(
                "‚¨áÔ∏è Baixar resultados com predi√ß√µes",
                data=csv_bytes,
                file_name="predicoes_evasao.csv",
                mime="text/csv",
            )

